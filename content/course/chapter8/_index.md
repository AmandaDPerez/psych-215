---
# Title, summary, and page position.
linktitle: Chapter 8
summary: Chapter 8
weight: 1
icon: book
icon_pack: fas

# Page metadata.
title: Chapter 8
date: "2018-09-09T00:00:00Z"
type: book  # Do not modify.
---

# Correlation

**First, watch the below crash course video on correlations**

[![Crash Course](http://img.youtube.com/vi/GtV-VYdNt_g/0.jpg)](http://www.youtube.com/watch?v=GtV-VYdNt_g "Correlation Crash Course")


## Introducing Bivariate Correlations

**Bivariate correlations**: associations that involve exactly two variables

You can describe associations between two quantitative variables

You can describe associations with one categorical and one numerical variable too

## A Study with All Measured Variables Is Correlational

What makes a study correlational? **Having two measured variables**

**Association claims**: 

* can be graphed using scatterplots or bar graphs

* can be made using r or t tests

When making an association claim, the kind of graph you make or the kind of statistic you use aren't important, *but having two measured variables is.*

## Interrogating Association Claims

**Construct validity: How well was each variable measured?**

Ask about the construct validity of each variable.

* How well was each of the variables measured?

* Does the measure have good reliability? 

* Is it measuring what it's intended to measure? 

* What is the evidence for its face validity, for its concurrent validity, and for its discriminant and convergent validity?

* For ex: In the Mehl study, you would ask questions about the researchers' operationalizations of deep talk and well-being. Deep talk in this study was observed via the EAR recordings and coded later by research assistants, while well-being was measured using the subjective well-being (SWB) scale.





**Statistical validity: How well do the data support the conclusion?**

* What is the effect size? describes the strength of an association


**Larger Effect Sizes Give More Accurate Predictions** 

When everything else is equal, a larger effect size is usually considered more important than a small one. But there are some exceptions.

**Small Effect Sizes Can Be Important Too**

Depending on the context, even a small effect size can be important. 
For ex, in a medical study on heart attacks and taking aspirin, a small r (r = .03) was considered extremely important because of the number of lives saved. There were 22,000 participants in the study, 11,000 in the aspirin group and 11,000 in the placebo group. There were 85 fewer heart attacks in the aspirin group. That's a lot of lives saved for a small effect size! But when the outcome isn't as extreme as life or death, then a small effect size might not be important.  

* Is the correlation statistically significant? The more strongly correlated two variables are, the more accurate our predictions can be.  

**Statistical significance** refers to the conclusion researchers make regarding how probable it is that they would get a correlation of that size by chance, assuming that there is not a correlation in the real world.

* The logic of statistical inference

* What does a statistically significant result mean?

A probability estimate (or p value) provides information about statistical significance by evaluating the probability that the association in the sample came from a population with an association of zero.
 
If p is very small (less than 5%), then it's very unlikely that the result came from a zero association. 
Thus, a finding of p < .05 is considered to be statistically significant.

* What does a nonsignificant result mean?

If p is relatively high (greater than .05), then the result is nonsignificant  (not statistically significant).
Therefore, we can't rule out the possibility that the result came from a zero-association population.

* Effect size, sample size, and significance 

Usually the stronger a correlation (i.e., the larger its effect size), the more likely it is that the correlation will be statistically significant. 

But we need to examine the p value, which is dependent on both effect size and sample size. 

A very small effect might be statistically significant for a large sample but not for a small sample. Small samples are more easily influenced by chance events than large samples.


**The logic of statistical inference**: Researchers collect data from a sample and make inferences to the population. 

If there's an association between two variables in the population, then there is usually an association in the sample. If there's no association between two variables in the population of interest, then there's probably no association in the sample. 

But sometimes even if there isn't an association in the population, simply by chance there may be an association in the sample. 

Calculations of statistical significance help researchers evaluate the probability that the result came from a population in which the association is actually zero.


* Could outliers be affecting the association?

An **outlier** is an extreme score (or perhaps a few) that lies far away from the rest of the scores. Outliers can cause problems for association claims because they may exert a large amount of influence. In bivariate correlations, outliers are most problematic when they involve extreme scores on both variables. Outliers are most influential when the sample is small. 

* Is the association curvilinear?

A **curvilinear association** is one in which the correlation coefficient is zero (or close to zero), and the relationship between two variables isn't a straight line

* Internal validity: Can we make a causal inference from association?

* External validity: To whom can the association be generalized?

## Applying the Three Causal Criteria

**Correlation is not causation**. In order to make a causal claim, a study has to satisfy these three criteria:

## How Important Is External Validity?

If a bivariate correlational study fails to use a random sample, it should not cause us to automatically reject the association. 

Instead we can accept the results as they are and save the question of generalizability for another study that tests the same variables in a different population. 

Also, many associations generalize to samples that are very different from the original sample. 

## Moderating Variables

**Moderator**: When the relationship between two variables changes depending on the level of another variable, that other variable is called a **moderator**.

Let's consider a study on the correlation between professional sports games attendance and the success of the team. 

Using data gathered over many major league baseball seasons, Oishi and his team determined that in cities with high residential mobility, there is a positive correlation between success and attendance, indicating a fair-weather (band-wagon) fan base. 

In cities with low residential mobility, there is not a significant correlation between success and attendance. 

We say that the degree of residential mobility moderates the relationship between success and attendance. (Source: Adapted from Oishi et al., 2007.)

