---
linktitle: Chapter 10
summary: Chapter 10
weight: 20
icon: book
icon_pack: fas
title: Chapter 10
date: "2018-09-09T00:00:00Z"
type: book  # Do not modify.
editor_options: 
  markdown: 
    wrap: 72
---

# Simple Experiments

**First, watch the below video on simple experiments**

[![Psych
Explained](https://img.youtube.com/vi/B2GcTIJYIZI/0.jpg)](http://www.youtube.com/watch?v=B2GcTIJYIZI%22Psychology%20Experiments%22)

## Experimental Variables

**Experiment:** at least one variable was manipulated (IV) and at least
one variable was measured (DV) by the researcher.

**Manipulated variable:** researcher assigns participants to a
particular level of the variable; example: notetaking method (levels:
computer, longhand)

**Measured variable:** research records what happens in terms of
behavior of attitudes based on self-report, behavioral observations, or
physiological measures; example: number of anagrams solved correctly.

## Independent and Dependent Variables

**Independent variable (IV):** manipulated Conditions: levels of an
independent variable

**Dependent variable (DV):** measured, outcome variable

## Control Variables

**Control variable:** any variable that an experimenter holds constant

**Example:** In a study about pasta preference testing different types
of pastas, all participants ate from the same type and size of plate.

## Why Experiments Support Causal Claims

Experiments establish covariance

Experiments establish temporal precedence

Well-designed experiments establish internal validity

### Experiments Establish Covariance

Independent variables answer the question, *"Compared to what?"*

-   **Comparison group** (comparison condition)

Covariance: it is also about the results

Control groups, treatment groups, and comparison groups

-   Control group (no treatment condition)

-   Treatment group(s) (one or more treatment conditions)

-   Placebo group (placebo control group)

### Experiments Establish Temporal Precedence

The cause variable precedes the effect variable.

serving bowl size &\#8594 amount of pasta (g)

### Well-Designed Experiments Establish Internal Validity

Confounds are these alternative explanations, and they can threaten
internal validity.

## Design Confounds

What is a **design confound**? There is a **design confound** when a
second variable varies systematically along with the IV and provides an
alternative explanation for the results.

Systematic variability is the problem

-   Systematic variability: can control with the way you design your
    study

-   Unsystematic variability: cannot control, just have to acknowledge

## Selection Effects

A **selection effect** occurs in an experiment when the participants in
one level of the IV are systematically different than the participants
in the other level or levels of the IV.

For example, Lovaas (1987) conducted a study to test an intensive
therapy for children with autism. Some children in the study received
the new treatment and others continued their usual treatment. However,
they were not randomly assigned to these groups because some families
lived too far away for the intensive treatment, and other families
requested the intensive treatment.

The researchers found that the autistic symptoms of children in the
intensive treatment group showed more improvement than those in the
treatment as usual group. However, this study had a selection effect in
which families in the intensive treatment group were probably
systematically different than those in the treatment as usual group.
Therefore, it's impossible to determine the reason for the improvement
because of this selection effect.

**Avoiding selection effects with random assignment:** Random assignment
is a way of assigning participants to levels of the IV such that each
participant has an equal chance of being in each group. There should be
no systematic difference between groups with random assignment. See the
figure on the slide.

## Independent-Groups Designs

Independent-groups design (aka between-subjects design or between-groups
design)

EX. Participants take notes EITHER with laptop OR with pen & paper.
Different people in each group.

### Posttest-only design (aka equivalent groups, posttest-only design)

A type of independent-groups experiment in which participants are
randomly assigned to IV groups and are tested on the DV just once.

### Pretest/Posttest Design

In a pretest/posttest design, or an equivalent groups, pretest/posttest
design, participants are randomly assigned to at least two different
groups and are tested on the key dependent variable twice---once before
and once after exposure to the independent variable.

Example: A study on the effects of mindfulness training, introduced in
Chapter 1, is an example of a pretest/posttest design. In this study, 48
students were randomly assigned to participate in either a 2-week
mindfulness class or a 2-week nutrition class (Mrazek, Franklin,
Phillips, Baird, & Schooler, 2013).

One week before starting their respective classes, all students
completed a verbal-reasoning section of a Graduate Record Examinations
(GRE) test. One week after their classes ended, all students completed
another verbal-reasoning GRE test of the same difficulty.

## Within-Groups Designs

Within-groups design (aka within-subjects design)

EX. Participants took notes BOTH with laptop and then at a later time
with pen & paper. Same people in each group.

### Repeated-Measures Design

A repeated-measures design is a type of within-groups design in which
participants are measured on the DV more than once (after exposure to
each level of the IV).

### Concurrent-measures designs

Participants are exposed to all levels of the IV at roughly the same
time, and a single preference is the DV.

### Advantages of Within-Groups Designs

Participants in your groups are equivalent because they are the same
participants and serve as their own controls.

These designs give researchers more power to notice differences between
conditions.

Within-groups designs require fewer participants than other designs.

### Internal Validity: Controlling for Order Effects

**Order effects** are when being exposed to one condition affects how
participants respond to other conditions:

**Practice effects:** occurs when participants either get better at a
task from practice or get worse at a task due to fatigue (called a
fatigue effect).

**Carryover effects:** This occurs when there is contamination carrying
over from one condition to the next. Ex: You drink caffeinated coffee
and then take a test. Then you drink decaf coffee and take a test.
However, the caffeinated coffee is still having an effect on you on the
second test.

Avoid order effects by counterbalancing the order of the conditions per
participant.

### Disadvantages of Within-Groups Designs

1.  Repeated-measures designs can have order effects, but those can be
    controlled for using counterbalancing.
2.  Within-groups designs are sometimes not practical or possible;
    example: Suppose someone has devised a new way of teaching children
    how to ride a bike, called Method A. She wants to compare Method A
    with the older method, Method B. Obviously, she cannot teach a group
    of children to ride a bike with Method A and then return them to
    baseline and teach them again with Method B. Once taught, the
    children are permanently changed. In such a case, a within-groups
    design, with or without counterbalancing, would make no sense.
3.  **Demand characteristics** (aka experimental demand) occur when
    participants pick up on cues that lead them to guess the
    experiment's hypothesis.

## Pretest/Posttest Design Versus Repeated-Measures Design

Should a pretest/posttest independent-groups design be considered a
within-groups design because participants are tested twice (once at
pretest and once at posttest)? It's important to remember that in a true
within-groups design, participants are exposed to all levels of the IV,
and the levels can be counterbalanced. But in a pretest/posttest design,
participants experience only one level of the IV (not all levels).

## Interrogating Causal Claims with the Four Validities

Construct validity: *How well were the variables measured and
manipulated?*

External validity: *To whom or what can the causal claim generalize?*

Statistical validity: *How well do the data support the causal claim?*

Internal validity: *Are there alternative explanations for the outcome?*

### Construct Validity: How Well Were the Variables Measured and Manipulated?

1.  Dependent variables: How well were they measured?

2.  Independent variables: How well were they manipulated

    **Manipulation check:** an extra dependent variable that researchers
    can insert into an experiment to convince them that their
    experimental manipulation worked.

    **Pilot study:** A simple study, using a separate group of
    participants, that is completed either before or, sometimes, after
    conducting the study of primary interest. Researchers may use pilot
    study data to confirm the effectiveness of their manipulations
    before using them in a target study.

### External Validity: To Whom or What Can the Causal Claim Generalize?

Generalizing to other people

Generalizing to other situations

*What if external validity is poor?* Remember that in an experiment, the
validity that is emphasized most is internal validity (i.e.,
experimental control). In order to achieve experimental control,
researchers sometimes conduct their studies in artificial laboratory
environments that may not represent the real world. Many experiments
sacrifice real-world representativeness in exchange for internal
validity.

### Statistical Validity: How Well Do the Data Support the Causal Claim?

Is the difference statistically significant?

**p \< 0.05\* (the smaller the better)**

p \< 0.01 **\*\***

p \< 0.001 \*\*\*

How large is the effect?

### Internal Validity: Are There Alternative Explanations for the Outcome?

Three fundamental questions about internal validity

1\. Were there any design confounds?

2\. If an independent (between)-groups design was used, did researchers
control for selection effects using random assignment?

3\. If a within-groups design was used, did researchers control for
order effects by counterbalancing?
